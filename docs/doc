We use google vision api which analyse the pictures and send us the results. The results contains the type of picture, whether it's adult,
violent, and etc. There are some other data but these types is the most useful.
We did not consider other same type of apis because google vision seems to be working pretty well, and the way to manage the result is clear.

---2018.3.28 Update---
We add Instagram api and create a webpage. The Instagram api is hard to use so we consider first hard-code the pictures and connect 
Instagram and google vision. Which means we do not need the user to input a user name but just use several pictures we prepared.(demo version)
The webpage alpha version is just a skeleton to present the result but nothing else.





"""TO RUN: must have this file and the apikey.json file in the same folder. 

Then must write in command line: 'export GOOGLE_APPLICATION_CREDENTIALS=apikey.json'. 

Then to run you have to download a picture into the folder and then add the picture name as an argument...
python visionex.py pictureName          

This will output the safe_search api which is basically if the picture is violent, for adults, about injuries(medical)
and inappropriate context overall. 

The code i have commented out is to use the labels api which just describes what 
is shown in the picture with basic labels (nothing to do with violence but very descriptive). 

"""
